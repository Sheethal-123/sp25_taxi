{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Sheethal-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Sheethal-\u001b[1;36m123\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Sheethal-123/sp25_taxi\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Sheethal-123/sp25_taxi\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Sheethal-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>/sp25_taxi initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Sheethal-\u001b[1;36m123\u001b[0m/sp25_taxi initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Now you can import from src\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner=\"Sheethal-123\", repo_name=\"sp25_taxi\", mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists for 2022-01.\n",
      "Loading data for 2022-01...\n",
      "Total records: 2,463,931\n",
      "Valid records: 2,415,141\n",
      "Records dropped: 48,790 (1.98%)\n",
      "Successfully processed data for 2022-01.\n",
      "File already exists for 2022-02.\n",
      "Loading data for 2022-02...\n",
      "Total records: 2,979,431\n",
      "Valid records: 2,921,118\n",
      "Records dropped: 58,313 (1.96%)\n",
      "Successfully processed data for 2022-02.\n",
      "File already exists for 2022-03.\n",
      "Loading data for 2022-03...\n",
      "Total records: 3,627,882\n",
      "Valid records: 3,551,986\n",
      "Records dropped: 75,896 (2.09%)\n",
      "Successfully processed data for 2022-03.\n",
      "File already exists for 2022-04.\n",
      "Loading data for 2022-04...\n",
      "Total records: 3,599,920\n",
      "Valid records: 3,522,113\n",
      "Records dropped: 77,807 (2.16%)\n",
      "Successfully processed data for 2022-04.\n",
      "File already exists for 2022-05.\n",
      "Loading data for 2022-05...\n",
      "Total records: 3,588,295\n",
      "Valid records: 3,509,056\n",
      "Records dropped: 79,239 (2.21%)\n",
      "Successfully processed data for 2022-05.\n",
      "File already exists for 2022-06.\n",
      "Loading data for 2022-06...\n",
      "Total records: 3,558,124\n",
      "Valid records: 3,479,411\n",
      "Records dropped: 78,713 (2.21%)\n",
      "Successfully processed data for 2022-06.\n",
      "File already exists for 2022-07.\n",
      "Loading data for 2022-07...\n",
      "Total records: 3,174,394\n",
      "Valid records: 3,096,271\n",
      "Records dropped: 78,123 (2.46%)\n",
      "Successfully processed data for 2022-07.\n",
      "File already exists for 2022-08.\n",
      "Loading data for 2022-08...\n",
      "Total records: 3,152,677\n",
      "Valid records: 3,072,196\n",
      "Records dropped: 80,481 (2.55%)\n",
      "Successfully processed data for 2022-08.\n",
      "File already exists for 2022-09.\n",
      "Loading data for 2022-09...\n",
      "Total records: 3,183,767\n",
      "Valid records: 3,106,359\n",
      "Records dropped: 77,408 (2.43%)\n",
      "Successfully processed data for 2022-09.\n",
      "File already exists for 2022-10.\n",
      "Loading data for 2022-10...\n",
      "Total records: 3,675,411\n",
      "Valid records: 3,583,466\n",
      "Records dropped: 91,945 (2.50%)\n",
      "Successfully processed data for 2022-10.\n",
      "File already exists for 2022-11.\n",
      "Loading data for 2022-11...\n",
      "Total records: 3,252,717\n",
      "Valid records: 3,165,474\n",
      "Records dropped: 87,243 (2.68%)\n",
      "Successfully processed data for 2022-11.\n",
      "File already exists for 2022-12.\n",
      "Loading data for 2022-12...\n",
      "Total records: 3,399,549\n",
      "Valid records: 3,310,530\n",
      "Records dropped: 89,019 (2.62%)\n",
      "Successfully processed data for 2022-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "File already exists for 2023-01.\n",
      "Loading data for 2023-01...\n",
      "Total records: 3,066,766\n",
      "Valid records: 2,993,140\n",
      "Records dropped: 73,626 (2.40%)\n",
      "Successfully processed data for 2023-01.\n",
      "File already exists for 2023-02.\n",
      "Loading data for 2023-02...\n",
      "Total records: 2,913,955\n",
      "Valid records: 2,845,058\n",
      "Records dropped: 68,897 (2.36%)\n",
      "Successfully processed data for 2023-02.\n",
      "File already exists for 2023-03.\n",
      "Loading data for 2023-03...\n",
      "Total records: 3,403,766\n",
      "Valid records: 3,331,705\n",
      "Records dropped: 72,061 (2.12%)\n",
      "Successfully processed data for 2023-03.\n",
      "File already exists for 2023-04.\n",
      "Loading data for 2023-04...\n",
      "Total records: 3,288,250\n",
      "Valid records: 3,214,922\n",
      "Records dropped: 73,328 (2.23%)\n",
      "Successfully processed data for 2023-04.\n",
      "File already exists for 2023-05.\n",
      "Loading data for 2023-05...\n",
      "Total records: 3,513,649\n",
      "Valid records: 3,435,875\n",
      "Records dropped: 77,774 (2.21%)\n",
      "Successfully processed data for 2023-05.\n",
      "File already exists for 2023-06.\n",
      "Loading data for 2023-06...\n",
      "Total records: 3,307,234\n",
      "Valid records: 3,233,969\n",
      "Records dropped: 73,265 (2.22%)\n",
      "Successfully processed data for 2023-06.\n",
      "File already exists for 2023-07.\n",
      "Loading data for 2023-07...\n",
      "Total records: 2,907,108\n",
      "Valid records: 2,838,637\n",
      "Records dropped: 68,471 (2.36%)\n",
      "Successfully processed data for 2023-07.\n",
      "File already exists for 2023-08.\n",
      "Loading data for 2023-08...\n",
      "Total records: 2,824,209\n",
      "Valid records: 2,758,739\n",
      "Records dropped: 65,470 (2.32%)\n",
      "Successfully processed data for 2023-08.\n",
      "File already exists for 2023-09.\n",
      "Loading data for 2023-09...\n",
      "Total records: 2,846,722\n",
      "Valid records: 2,782,920\n",
      "Records dropped: 63,802 (2.24%)\n",
      "Successfully processed data for 2023-09.\n",
      "File already exists for 2023-10.\n",
      "Loading data for 2023-10...\n",
      "Total records: 3,522,285\n",
      "Valid records: 3,446,406\n",
      "Records dropped: 75,879 (2.15%)\n",
      "Successfully processed data for 2023-10.\n",
      "File already exists for 2023-11.\n",
      "Loading data for 2023-11...\n",
      "Total records: 3,339,715\n",
      "Valid records: 3,267,940\n",
      "Records dropped: 71,775 (2.15%)\n",
      "Successfully processed data for 2023-11.\n",
      "File already exists for 2023-12.\n",
      "Loading data for 2023-12...\n",
      "Total records: 3,376,567\n",
      "Valid records: 3,313,957\n",
      "Records dropped: 62,610 (1.85%)\n",
      "Successfully processed data for 2023-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n"
     ]
    }
   ],
   "source": [
    "rides1 = load_and_process_taxi_data(year=2022)\n",
    "rides2=(load_and_process_taxi_data(year=2023))\n",
    "rides = pd.concat([rides1,rides2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_rides = rides[rides[\"pickup_location_id\"] == 43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheet\\github\\sp25_taxi\\src\\data_utils.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rides[\"pickup_hour\"] = rides[\"pickup_datetime\"].dt.floor(\"h\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour  pickup_location_id  rides\n",
       "0 2022-01-01 00:00:00                  43     96\n",
       "1 2022-01-01 01:00:00                  43     60\n",
       "2 2022-01-01 02:00:00                  43     22\n",
       "3 2022-01-01 03:00:00                  43      8\n",
       "4 2022-01-01 04:00:00                  43      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(temp_rides)\n",
    "ts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17516</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17517</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17518</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17519</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pickup_hour  pickup_location_id  rides\n",
       "0     2022-01-01 00:00:00                  43     96\n",
       "1     2022-01-01 01:00:00                  43     60\n",
       "2     2022-01-01 02:00:00                  43     22\n",
       "3     2022-01-01 03:00:00                  43      8\n",
       "4     2022-01-01 04:00:00                  43      4\n",
       "...                   ...                 ...    ...\n",
       "17515 2023-12-31 19:00:00                  43     55\n",
       "17516 2023-12-31 20:00:00                  43     72\n",
       "17517 2023-12-31 21:00:00                  43     50\n",
       "17518 2023-12-31 22:00:00                  43     28\n",
       "17519 2023-12-31 23:00:00                  43     34\n",
       "\n",
       "[17520 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.drop(columns=[\"pickup_location_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pickup_hour  rides\n",
      "0 2022-01-01 00:00:00     96\n",
      "1 2022-01-01 01:00:00     60\n",
      "2 2022-01-01 02:00:00     22\n",
      "3 2022-01-01 03:00:00      8\n",
      "4 2022-01-01 04:00:00      4\n"
     ]
    }
   ],
   "source": [
    "print(ts_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,0,2)(0,0,0)[0]             : AIC=162977.313, Time=4.30 sec\n",
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=210122.120, Time=0.21 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0]             : AIC=165205.279, Time=0.27 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0]             : AIC=191455.692, Time=1.51 sec\n",
      " ARIMA(1,0,2)(0,0,0)[0]             : AIC=164599.482, Time=2.83 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0]             : AIC=164969.807, Time=3.43 sec\n",
      " ARIMA(3,0,2)(0,0,0)[0]             : AIC=inf, Time=14.43 sec\n",
      " ARIMA(2,0,3)(0,0,0)[0]             : AIC=162484.750, Time=6.34 sec\n",
      " ARIMA(1,0,3)(0,0,0)[0]             : AIC=163384.864, Time=4.10 sec\n",
      " ARIMA(3,0,3)(0,0,0)[0]             : AIC=162468.514, Time=7.59 sec\n",
      " ARIMA(4,0,3)(0,0,0)[0]             : AIC=159187.020, Time=18.03 sec\n",
      " ARIMA(4,0,2)(0,0,0)[0]             : AIC=162619.471, Time=6.04 sec\n",
      " ARIMA(5,0,3)(0,0,0)[0]             : AIC=162611.454, Time=19.03 sec\n",
      " ARIMA(4,0,4)(0,0,0)[0]             : AIC=156857.325, Time=23.83 sec\n",
      " ARIMA(3,0,4)(0,0,0)[0]             : AIC=162451.439, Time=11.33 sec\n",
      " ARIMA(5,0,4)(0,0,0)[0]             : AIC=inf, Time=23.98 sec\n",
      " ARIMA(4,0,5)(0,0,0)[0]             : AIC=161957.722, Time=21.79 sec\n",
      " ARIMA(3,0,5)(0,0,0)[0]             : AIC=159024.825, Time=24.34 sec\n",
      " ARIMA(5,0,5)(0,0,0)[0]             : AIC=161665.229, Time=25.01 sec\n",
      " ARIMA(4,0,4)(0,0,0)[0] intercept   : AIC=158532.574, Time=43.66 sec\n",
      "\n",
      "Best model:  ARIMA(4,0,4)(0,0,0)[0]          \n",
      "Total fit time: 262.093 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                17520\n",
      "Model:               SARIMAX(4, 0, 4)   Log Likelihood              -78419.662\n",
      "Date:                Wed, 05 Mar 2025   AIC                         156857.325\n",
      "Time:                        03:29:58   BIC                         156927.264\n",
      "Sample:                             0   HQIC                        156880.354\n",
      "                              - 17520                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          2.8957      0.021    135.265      0.000       2.854       2.938\n",
      "ar.L2         -2.8338      0.062    -45.382      0.000      -2.956      -2.711\n",
      "ar.L3          0.9103      0.062     14.654      0.000       0.789       1.032\n",
      "ar.L4          0.0276      0.021      1.311      0.190      -0.014       0.069\n",
      "ma.L1         -2.2414      0.021   -107.077      0.000      -2.282      -2.200\n",
      "ma.L2          1.3050      0.049     26.527      0.000       1.209       1.401\n",
      "ma.L3          0.2391      0.038      6.244      0.000       0.164       0.314\n",
      "ma.L4         -0.2916      0.010    -28.810      0.000      -0.311      -0.272\n",
      "sigma2       411.5845      2.852    144.314      0.000     405.995     417.174\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   3.48   Jarque-Bera (JB):              3709.67\n",
      "Prob(Q):                              0.06   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.96   Skew:                             0.34\n",
      "Prob(H) (two-sided):                  0.14   Kurtosis:                         5.15\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# Find best ARIMA(p, d, q)\n",
    "model_auto = auto_arima(ts_data[\"rides\"], seasonal=False, stepwise=True, trace=True)\n",
    "\n",
    "# Print the best parameters\n",
    "print(model_auto.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheet\\anaconda3\\envs\\sp25_taxi\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                  rides   No. Observations:                17520\n",
      "Model:                 ARIMA(4, 0, 4)   Log Likelihood              -78007.557\n",
      "Date:                Wed, 05 Mar 2025   AIC                         156035.115\n",
      "Time:                        03:30:37   BIC                         156112.826\n",
      "Sample:                             0   HQIC                        156060.704\n",
      "                              - 17520                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         73.4146      0.780     94.164      0.000      71.887      74.943\n",
      "ar.L1          1.6913      0.007    249.310      0.000       1.678       1.705\n",
      "ar.L2          0.2235      0.006     34.628      0.000       0.211       0.236\n",
      "ar.L3         -1.7064      0.006   -266.684      0.000      -1.719      -1.694\n",
      "ar.L4          0.7588      0.007    112.176      0.000       0.746       0.772\n",
      "ma.L1         -1.0889      0.009   -115.649      0.000      -1.107      -1.070\n",
      "ma.L2         -0.7810      0.009    -90.446      0.000      -0.798      -0.764\n",
      "ma.L3          1.1449      0.009    130.967      0.000       1.128       1.162\n",
      "ma.L4         -0.1623      0.009    -17.526      0.000      -0.180      -0.144\n",
      "sigma2       445.7517      3.470    128.448      0.000     438.950     452.553\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   1.02   Jarque-Bera (JB):              3673.21\n",
      "Prob(Q):                              0.31   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.96   Skew:                             0.28\n",
      "Prob(H) (two-sided):                  0.09   Kurtosis:                         5.17\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit the best ARIMA model (Example: ARIMA(4, 0, 4) if suggested)\n",
    "model_arima = ARIMA(ts_data[\"rides\"], order=(4, 0, 4))  # Replace with best (p, d, q)\n",
    "arima_result = model_arima.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(arima_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheet\\anaconda3\\envs\\sp25_taxi\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for ARIMA: 24.49473499282344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Split data into train (80%) and test (20%)\n",
    "train_size = int(len(ts_data) * 0.8)\n",
    "train, test = ts_data.iloc[:train_size], ts_data.iloc[train_size:]\n",
    "\n",
    "# Fit ARIMA on training data\n",
    "model_arima = ARIMA(train[\"rides\"], order=(4, 0, 4))  # Use optimal (p,d,q)\n",
    "arima_result = model_arima.fit()\n",
    "\n",
    "# Forecast for test set\n",
    "forecast = arima_result.forecast(steps=len(test))\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(test[\"rides\"], forecast)\n",
    "print(\"Mean Absolute Error (MAE) for ARIMA:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 03:31:16 INFO mlflow.tracking.fluent: Experiment with name 'model_arima' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run welcoming-mare-293 at: https://dagshub.com/Sheethal-123/sp25_taxi.mlflow/#/experiments/6/runs/7a791cb45a99422e871ebb8dedd73739\n",
      "🧪 View experiment at: https://dagshub.com/Sheethal-123/sp25_taxi.mlflow/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"model_arima\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "        mlflow.log_metric(\"mean_absolute_error\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
